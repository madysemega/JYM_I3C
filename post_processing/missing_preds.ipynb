{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84ec7b18-a6b2-45a7-bd91-1e25a7db75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "Housing_Directory = 'housing'\n",
    "Commercial = ['Mall', 'Industrial', 'Office']\n",
    "commercial_targets = ['occupancy', 'rank_desirability', 'asset_value_momentum', 'remote_work_share']\n",
    "housing_targets = ['asset_value_momentum', 'remote_work_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f7c92b-d70f-45be-b140-51c2aafef409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_least_used_gpu():\n",
    "    # Implement a method to check GPU usage\n",
    "    # For example, using nvidia-smi (this is a basic implementation and might need refinement):\n",
    "    nvidia_smi_output = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader,nounits']).decode()\n",
    "    memory_usage = [int(x) for x in nvidia_smi_output.strip().split('\\n')]\n",
    "    return memory_usage.index(min(memory_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "055141cd-047f-4536-9c9f-1594951c6b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_least_used_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62109143-11ec-4393-8032-57e1d15b4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "States: 100%|██████████| 51/51 [00:00<00:00, 701.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions to make: 9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "to_predict = {}\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate through states\n",
    "for state in tqdm(os.listdir(Housing_Directory), desc='States'):\n",
    "    state_path = os.path.join(Housing_Directory, state)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(state_path):\n",
    "        \n",
    "        # Iterate through cities\n",
    "        for city in os.listdir(state_path):\n",
    "            city_path = os.path.join(state_path, city)\n",
    "            \n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(city_path):\n",
    "                \n",
    "                # Iterate through property types\n",
    "                for property_type in os.listdir(city_path):\n",
    "                    property_type_path = os.path.join(city_path, property_type)\n",
    "                    \n",
    "                    # Check if it's a directory\n",
    "                    if os.path.isdir(property_type_path):\n",
    "                        current_targets = commercial_targets if property_type in Commercial else housing_targets\n",
    "                        type = 'Commercial' if property_type in Commercial else 'Housing'\n",
    "                        \n",
    "                        # Check for missing target files\n",
    "                        missing_targets = [target + '.csv' for target in current_targets if not os.path.exists(os.path.join(property_type_path, target + '.csv'))]\n",
    "                        if missing_targets:\n",
    "                            to_predict[property_type_path] = (missing_targets, type)\n",
    "                            total_predictions += len(missing_targets)\n",
    "\n",
    "# Print the number of predictions to make\n",
    "print(f\"Total predictions to make: {total_predictions}\")\n",
    "\n",
    "# Write the to_predict dictionary to a JSON file\n",
    "with open('to_predict.json', 'w') as file:\n",
    "    json.dump(to_predict, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf987b51-33be-48fd-b24c-7f32fa269ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file at: housing/VA/Reston/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/VA/Herndon/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/IN/Fishers/Townhouse/dataset.csv\n",
      "Processing file at: housing/IN/Indianapolis/Townhouse/dataset.csv\n",
      "Processing file at: housing/CT/New Haven/Townhouse/dataset.csv\n",
      "Processing file at: housing/NC/Morganton/Townhouse/dataset.csv\n",
      "Processing file at: housing/NJ/Cherry Hill/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/TX/Sugar Land/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/TX/Killeen/Condo/dataset.csv\n",
      "Processing file at: housing/TX/Wichita Falls/Condo/dataset.csv\n",
      "Processing file at: housing/WI/Milwaukee/Townhouse/dataset.csv\n",
      "Processing file at: housing/WI/Wauwatosa/Townhouse/dataset.csv\n",
      "Processing file at: housing/IA/Cedar Rapids/Townhouse/dataset.csv\n",
      "Processing file at: housing/IA/Iowa City/Townhouse/dataset.csv\n",
      "Processing file at: housing/AZ/Goodyear/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/KY/Bowling Green/Townhouse/dataset.csv\n",
      "Processing file at: housing/LA/Bossier City/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/MI/East Lansing/Townhouse/dataset.csv\n",
      "Processing file at: housing/MI/Traverse City/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/OH/Lima/Condo/dataset.csv\n",
      "Processing file at: housing/CA/Aliso Viejo/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/CA/Vacaville/Townhouse/dataset.csv\n",
      "Processing file at: housing/CA/San Francisco/Office/dataset.csv\n",
      "Processing file at: housing/ND/Fargo/Single Family Residential/dataset.csv\n",
      "Processing file at: housing/ND/Fargo/All Residential/dataset.csv\n",
      "Processing file at: housing/OK/Lawton/Condo/dataset.csv\n",
      "Processing file at: housing/IL/Glenview/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/MN/Circle Pines/Condo/dataset.csv\n",
      "Processing file at: housing/MS/Olive Branch/Multi-Family (2-4 Unit)/dataset.csv\n",
      "Processing file at: housing/NY/Ithaca/Townhouse/dataset.csv\n",
      "Processing file at: housing/AK/Anchorage/Townhouse/dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "for property_type_path, _ in to_predict.items():\n",
    "    print(f'Processing file at: {property_type_path}/dataset.csv')\n",
    "    df = pd.read_csv(f'{property_type_path}/dataset.csv')\n",
    "    df = df.head(84)\n",
    "    df.to_csv(f'{property_type_path}/dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d98523-aabd-40b2-a653-cb29b1eebb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted housing/VA/Reston/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/VA/Herndon/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/IN/Fishers/Townhouse\n",
      "Successfully deleted housing/IN/Indianapolis/Townhouse\n",
      "Successfully deleted housing/CT/New Haven/Townhouse\n",
      "Successfully deleted housing/NC/Morganton/Townhouse\n",
      "Successfully deleted housing/NJ/Cherry Hill/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/TX/Sugar Land/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/TX/Killeen/Condo\n",
      "Successfully deleted housing/TX/Wichita Falls/Condo\n",
      "Successfully deleted housing/WI/Milwaukee/Townhouse\n",
      "Successfully deleted housing/WI/Wauwatosa/Townhouse\n",
      "Successfully deleted housing/IA/Cedar Rapids/Townhouse\n",
      "Successfully deleted housing/IA/Iowa City/Townhouse\n",
      "Successfully deleted housing/AZ/Goodyear/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/KY/Bowling Green/Townhouse\n",
      "Successfully deleted housing/LA/Bossier City/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/MI/East Lansing/Townhouse\n",
      "Successfully deleted housing/MI/Traverse City/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/OH/Lima/Condo\n",
      "Successfully deleted housing/CA/Aliso Viejo/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/CA/Vacaville/Townhouse\n",
      "Successfully deleted housing/ND/Fargo/Single Family Residential\n",
      "Successfully deleted housing/ND/Fargo/All Residential\n",
      "Successfully deleted housing/OK/Lawton/Condo\n",
      "Successfully deleted housing/IL/Glenview/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/MN/Circle Pines/Condo\n",
      "Successfully deleted housing/MS/Olive Branch/Multi-Family (2-4 Unit)\n",
      "Successfully deleted housing/NY/Ithaca/Townhouse\n",
      "Successfully deleted housing/AK/Anchorage/Townhouse\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Assuming to_predict is a dictionary with folder paths\n",
    "for folder_path in to_predict.keys():\n",
    "    try:\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Successfully deleted {folder_path}\")\n",
    "    except OSError as e:\n",
    "        print(f\"Error: {e.filename} - {e.strerror}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccb05dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "Housing_Directory = 'housing'\n",
    "Commercial = ['Mall', 'Industrial', 'Office']\n",
    "commercial_targets = ['occupancy', 'rank_desirability', 'asset_value_momentum', 'remote_work_share']\n",
    "housing_targets = ['asset_value_momentum', 'remote_work_share']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4408f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def get_least_used_gpu():\n",
    "    # Implement a method to check GPU usage\n",
    "    # For example, using nvidia-smi (this is a basic implementation and might need refinement):\n",
    "    nvidia_smi_output = subprocess.check_output(['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader,nounits']).decode()\n",
    "    memory_usage = [int(x) for x in nvidia_smi_output.strip().split('\\n')]\n",
    "    return memory_usage.index(min(memory_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ce7351d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_least_used_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638d593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "States: 100%|██████████| 51/51 [00:00<00:00, 728.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions to make: 3691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "to_predict = {}\n",
    "total_predictions = 0\n",
    "\n",
    "# Iterate through states\n",
    "for state in tqdm(os.listdir(Housing_Directory), desc='States'):\n",
    "    state_path = os.path.join(Housing_Directory, state)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(state_path):\n",
    "        \n",
    "        # Iterate through cities\n",
    "        for city in os.listdir(state_path):\n",
    "            city_path = os.path.join(state_path, city)\n",
    "            \n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(city_path):\n",
    "                \n",
    "                # Iterate through property types\n",
    "                for property_type in os.listdir(city_path):\n",
    "                    property_type_path = os.path.join(city_path, property_type)\n",
    "                    \n",
    "                    # Check if it's a directory\n",
    "                    if os.path.isdir(property_type_path):\n",
    "                        current_targets = commercial_targets if property_type in Commercial else housing_targets\n",
    "                        type = 'Commercial' if property_type in Commercial else 'Housing'\n",
    "                        \n",
    "                        # Check for missing target files\n",
    "                        missing_targets = [target + '.csv' for target in current_targets if not os.path.exists(os.path.join(property_type_path, target + '.csv'))]\n",
    "                        if missing_targets:\n",
    "                            to_predict[property_type_path] = (missing_targets, type)\n",
    "                            total_predictions += len(missing_targets)\n",
    "\n",
    "# Print the number of predictions to make\n",
    "print(f\"Total predictions to make: {total_predictions}\")\n",
    "\n",
    "# Write the to_predict dictionary to a JSON file\n",
    "with open('to_predict.json', 'w') as file:\n",
    "    json.dump(to_predict, file, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
